{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-19T14:54:55.554201Z",
     "start_time": "2025-10-19T14:54:48.151201Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import warnings\n",
    "import ast\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python3_10\\lib\\site-packages\\paramiko\\pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "C:\\python3_10\\lib\\site-packages\\paramiko\\transport.py:258: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:55:02.716201Z",
     "start_time": "2025-10-19T14:54:55.587202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = \"data/movies/\"\n",
    "\n",
    "movies_df = pd.read_csv(data_path + \"movies_metadata.csv\", low_memory=False)\n",
    "credits_df = pd.read_csv(data_path + \"credits.csv\")\n",
    "ratings_df = pd.read_csv(data_path + \"ratings.csv\")\n",
    "\n",
    "print(\"=== Movies Metadata ===\")\n",
    "print(f\"Shape: {movies_df.shape}\")\n",
    "print(f\"Columns: {list(movies_df.columns)}\")\n",
    "print(\"\\nSample:\")\n",
    "print(movies_df.head(2))\n",
    "\n",
    "print(\"\\n=== Credits ===\")\n",
    "print(f\"Shape: {credits_df.shape}\")\n",
    "print(f\"Columns: {list(credits_df.columns)}\")\n",
    "print(\"\\nSample:\")\n",
    "print(credits_df.head(2))\n",
    "\n",
    "print(\"\\n=== Ratings ===\")\n",
    "print(f\"Shape: {ratings_df.shape}\")\n",
    "print(f\"Columns: {list(ratings_df.columns)}\")\n",
    "print(\"\\nSample:\")\n",
    "print(ratings_df.head(2))"
   ],
   "id": "84dd3063ee3ac92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Movies Metadata ===\n",
      "Shape: (45466, 24)\n",
      "Columns: ['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'production_companies', 'production_countries', 'release_date', 'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title', 'video', 'vote_average', 'vote_count']\n",
      "\n",
      "Sample:\n",
      "   adult                              belongs_to_collection    budget  \\\n",
      "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
      "1  False                                                NaN  65000000   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
      "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "\n",
      "                               homepage    id    imdb_id original_language  \\\n",
      "0  http://toystory.disney.com/toy-story   862  tt0114709                en   \n",
      "1                                   NaN  8844  tt0113497                en   \n",
      "\n",
      "  original_title                                           overview  ...  \\\n",
      "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
      "1        Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
      "\n",
      "  release_date      revenue runtime  \\\n",
      "0   1995-10-30  373554033.0    81.0   \n",
      "1   1995-12-15  262797249.0   104.0   \n",
      "\n",
      "                                    spoken_languages    status  \\\n",
      "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
      "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
      "\n",
      "                                     tagline      title  video vote_average  \\\n",
      "0                                        NaN  Toy Story  False          7.7   \n",
      "1  Roll the dice and unleash the excitement!    Jumanji  False          6.9   \n",
      "\n",
      "  vote_count  \n",
      "0     5415.0  \n",
      "1     2413.0  \n",
      "\n",
      "[2 rows x 24 columns]\n",
      "\n",
      "=== Credits ===\n",
      "Shape: (45476, 3)\n",
      "Columns: ['cast', 'crew', 'id']\n",
      "\n",
      "Sample:\n",
      "                                                cast  \\\n",
      "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
      "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
      "\n",
      "                                                crew    id  \n",
      "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...   862  \n",
      "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...  8844  \n",
      "\n",
      "=== Ratings ===\n",
      "Shape: (26024289, 4)\n",
      "Columns: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "\n",
      "Sample:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      110     1.0  1425941529\n",
      "1       1      147     4.5  1425942435\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:55:25.847351Z",
     "start_time": "2025-10-19T14:55:05.059202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def safe_parse_json_field(field):\n",
    "    try:\n",
    "        if pd.isna(field):\n",
    "            return []\n",
    "        return ast.literal_eval(field)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def extract_names(json_list, key='name'):\n",
    "    if not json_list:\n",
    "        return []\n",
    "    return [item.get(key, '') for item in json_list if isinstance(item, dict)]\n",
    "\n",
    "def extract_directors(crew_list):\n",
    "    if not crew_list:\n",
    "        return []\n",
    "    return [item.get('name', '') for item in crew_list\n",
    "            if isinstance(item, dict) and item.get('job') == 'Director']\n",
    "\n",
    "print(\"Processing genres...\")\n",
    "movies_df['genres_parsed'] = movies_df['genres'].apply(safe_parse_json_field)\n",
    "movies_df['genres_list'] = movies_df['genres_parsed'].apply(lambda x: extract_names(x))\n",
    "movies_df['genres_str'] = movies_df['genres_list'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "print(\"Processing credits...\")\n",
    "credits_df['cast_parsed'] = credits_df['cast'].apply(safe_parse_json_field)\n",
    "credits_df['crew_parsed'] = credits_df['crew'].apply(safe_parse_json_field)\n",
    "credits_df['actors_list'] = credits_df['cast_parsed'].apply(lambda x: extract_names(x))\n",
    "credits_df['directors_list'] = credits_df['crew_parsed'].apply(extract_directors)\n",
    "credits_df['actors_str'] = credits_df['actors_list'].apply(lambda x: ' '.join(x[:5]))\n",
    "credits_df['directors_str'] = credits_df['directors_list'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "print(\"Fixing id types...\")\n",
    "movies_df['id'] = pd.to_numeric(movies_df['id'], errors='coerce')\n",
    "credits_df['id'] = pd.to_numeric(credits_df['id'], errors='coerce')\n",
    "movies_df = movies_df.dropna(subset=['id'])\n",
    "credits_df = credits_df.dropna(subset=['id'])\n",
    "movies_df['id'] = movies_df['id'].astype(int)\n",
    "credits_df['id'] = credits_df['id'].astype(int)\n",
    "\n",
    "print(\"Merging datasets...\")\n",
    "df = movies_df.merge(credits_df[['id', 'actors_str', 'directors_str', 'actors_list', 'directors_list']],\n",
    "                     on='id', how='inner')\n",
    "\n",
    "print(\"Cleaning data...\")\n",
    "df = df.dropna(subset=['overview', 'release_date', 'genres_str'])\n",
    "df = df[df['overview'].str.len() > 20]\n",
    "df = df[df['genres_str'].str.len() > 0]\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df = df.dropna(subset=['release_date'])\n",
    "df['year'] = df['release_date'].dt.year\n",
    "df = df[(df['year'] >= 1990) & (df['year'] <= 2023)]\n",
    "\n",
    "print(\"Creating temporal splits...\")\n",
    "train_df = df[df['year'] < 2010].copy()\n",
    "val_df = df[(df['year'] >= 2010) & (df['year'] < 2015)].copy()\n",
    "test_df = df[df['year'] >= 2015].copy()\n",
    "\n",
    "print(\"Creating ground truth from vote_average...\")\n",
    "df['is_high_rated'] = (df['vote_average'] >= 6.0) & (df['vote_count'] >= 10)\n",
    "\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "print(f\"High rated movies: {df['is_high_rated'].sum()}\")\n",
    "print(f\"\\nSample processed data:\")\n",
    "print(df[['title', 'year', 'genres_str', 'actors_str', 'directors_str', 'is_high_rated']].head(3))"
   ],
   "id": "84f7fe095c8078d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing genres...\n",
      "Processing credits...\n",
      "Fixing id types...\n",
      "Merging datasets...\n",
      "Cleaning data...\n",
      "Creating temporal splits...\n",
      "Creating ground truth from vote_average...\n",
      "Final dataset shape: (27610, 33)\n",
      "Train: 15576, Val: 8171, Test: 3863\n",
      "High rated movies: 9536\n",
      "\n",
      "Sample processed data:\n",
      "              title  year                genres_str  \\\n",
      "0         Toy Story  1995   Animation Comedy Family   \n",
      "1           Jumanji  1995  Adventure Fantasy Family   \n",
      "2  Grumpier Old Men  1995            Romance Comedy   \n",
      "\n",
      "                                          actors_str  directors_str  \\\n",
      "0  Tom Hanks Tim Allen Don Rickles Jim Varney Wal...  John Lasseter   \n",
      "1  Robin Williams Jonathan Hyde Kirsten Dunst Bra...   Joe Johnston   \n",
      "2  Walter Matthau Jack Lemmon Ann-Margret Sophia ...  Howard Deutch   \n",
      "\n",
      "   is_high_rated  \n",
      "0           True  \n",
      "1           True  \n",
      "2           True  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:55:33.642350Z",
     "start_time": "2025-10-19T14:55:25.866349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WORD2VEC_DIM = 100\n",
    "TOP_ACTORS = 500\n",
    "TOP_DIRECTORS = 200\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', str(text).lower()).split()\n",
    "\n",
    "print(\"Preparing corpus for Word2Vec...\")\n",
    "corpus = []\n",
    "for _, row in train_df.iterrows():\n",
    "    overview_words = preprocess_text(row['overview'])\n",
    "    genre_words = preprocess_text(row['genres_str'])\n",
    "    actor_words = preprocess_text(row['actors_str'])\n",
    "    director_words = preprocess_text(row['directors_str'])\n",
    "    corpus.append(overview_words + genre_words + actor_words + director_words)\n",
    "\n",
    "print(\"Training Word2Vec model...\")\n",
    "w2v_model = Word2Vec(sentences=corpus, vector_size=WORD2VEC_DIM, window=5,\n",
    "                     min_count=2, workers=4, epochs=10, seed=42)\n",
    "\n",
    "def get_word2vec_vector(text, model):\n",
    "    words = preprocess_text(text)\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "print(\"Creating overview vectors...\")\n",
    "df['overview_vector'] = df['overview'].apply(lambda x: get_word2vec_vector(x, w2v_model))\n",
    "\n",
    "print(\"Creating genre vectors...\")\n",
    "df['genre_vector'] = df['genres_str'].apply(lambda x: get_word2vec_vector(x, w2v_model))\n",
    "\n",
    "print(\"Finding top actors and directors...\")\n",
    "all_actors = []\n",
    "all_directors = []\n",
    "for _, row in train_df.iterrows():\n",
    "    all_actors.extend(row['actors_list'][:5])\n",
    "    all_directors.extend(row['directors_list'])\n",
    "\n",
    "actor_counts = Counter(all_actors)\n",
    "director_counts = Counter(all_directors)\n",
    "top_actors = [actor for actor, _ in actor_counts.most_common(TOP_ACTORS)]\n",
    "top_directors = [director for director, _ in director_counts.most_common(TOP_DIRECTORS)]\n",
    "\n",
    "print(f\"Top actors: {len(top_actors)}, Top directors: {len(top_directors)}\")\n",
    "\n",
    "def create_person_vector(person_list, top_persons):\n",
    "    vector = np.zeros(len(top_persons))\n",
    "    for person in person_list:\n",
    "        if person in top_persons:\n",
    "            idx = top_persons.index(person)\n",
    "            vector[idx] = 1\n",
    "    return vector\n",
    "\n",
    "print(\"Creating actor and director vectors...\")\n",
    "df['actor_vector'] = df['actors_list'].apply(lambda x: create_person_vector(x[:5], top_actors))\n",
    "df['director_vector'] = df['directors_list'].apply(lambda x: create_person_vector(x, top_directors))\n",
    "\n",
    "print(\"Creating temporal context features...\")\n",
    "year_scaler = MinMaxScaler()\n",
    "df['year_normalized'] = year_scaler.fit_transform(df[['year']])\n",
    "df['era'] = pd.cut(df['year'], bins=[1990, 2000, 2010, 2017, 2025],\n",
    "                   labels=['90s', '2000s', '2010s', '2020s'])\n",
    "era_encoder = LabelEncoder()\n",
    "df['era_encoded'] = era_encoder.fit_transform(df['era'])\n",
    "\n",
    "print(\"Final feature dimensions:\")\n",
    "print(f\"Overview: {WORD2VEC_DIM}\")\n",
    "print(f\"Genre: {WORD2VEC_DIM}\")\n",
    "print(f\"Actor: {len(top_actors)}\")\n",
    "print(f\"Director: {len(top_directors)}\")\n",
    "print(f\"Total feature dimension: {WORD2VEC_DIM * 2 + len(top_actors) + len(top_directors)}\")\n",
    "\n",
    "print(\"\\nSample vectors:\")\n",
    "sample_idx = 0\n",
    "print(f\"Movie: {df.iloc[sample_idx]['title']}\")\n",
    "print(f\"Overview vector shape: {df.iloc[sample_idx]['overview_vector'].shape}\")\n",
    "print(f\"Genre vector shape: {df.iloc[sample_idx]['genre_vector'].shape}\")\n",
    "print(f\"Actor vector shape: {df.iloc[sample_idx]['actor_vector'].shape}\")\n",
    "print(f\"Director vector shape: {df.iloc[sample_idx]['director_vector'].shape}\")"
   ],
   "id": "d750d1b485cdcb19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing corpus for Word2Vec...\n",
      "Training Word2Vec model...\n",
      "Creating overview vectors...\n",
      "Creating genre vectors...\n",
      "Finding top actors and directors...\n",
      "Top actors: 500, Top directors: 200\n",
      "Creating actor and director vectors...\n",
      "Creating temporal context features...\n",
      "Final feature dimensions:\n",
      "Overview: 100\n",
      "Genre: 100\n",
      "Actor: 500\n",
      "Director: 200\n",
      "Total feature dimension: 900\n",
      "\n",
      "Sample vectors:\n",
      "Movie: Toy Story\n",
      "Overview vector shape: (100,)\n",
      "Genre vector shape: (100,)\n",
      "Actor vector shape: (500,)\n",
      "Director vector shape: (200,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:55:34.033587Z",
     "start_time": "2025-10-19T14:55:33.711350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AttentionNetwork(nn.Module):\n",
    "    def __init__(self, context_dim=6, hidden_dims=[128, 64, 32], dropout=0.3):\n",
    "        super(AttentionNetwork, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        input_dim = context_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, 4))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, context):\n",
    "        return self.network(context)\n",
    "\n",
    "def compute_context_vector(movie1_idx, movie2_idx, df):\n",
    "    m1 = df.iloc[movie1_idx]\n",
    "    m2 = df.iloc[movie2_idx]\n",
    "\n",
    "    genre_sim = cosine_similarity([m1['genre_vector']], [m2['genre_vector']])[0][0]\n",
    "\n",
    "    year_diff = abs(m1['year'] - m2['year']) / 50.0\n",
    "    year_diff = min(year_diff, 1.0)\n",
    "\n",
    "    era_same = float(m1['era_encoded'] == m2['era_encoded'])\n",
    "\n",
    "    rating_diff = abs(m1['vote_average'] - m2['vote_average']) / 10.0\n",
    "\n",
    "    pop1 = pd.to_numeric(m1['popularity'], errors='coerce')\n",
    "    pop2 = pd.to_numeric(m2['popularity'], errors='coerce')\n",
    "    if pd.isna(pop1): pop1 = 1.0\n",
    "    if pd.isna(pop2): pop2 = 1.0\n",
    "    popularity_sim = 1.0 - abs(pop1 - pop2) / max(pop1, pop2, 1.0)\n",
    "    popularity_sim = max(popularity_sim, 0.0)\n",
    "\n",
    "    runtime1 = pd.to_numeric(m1.get('runtime', 100), errors='coerce')\n",
    "    runtime2 = pd.to_numeric(m2.get('runtime', 100), errors='coerce')\n",
    "    if pd.isna(runtime1): runtime1 = 100.0\n",
    "    if pd.isna(runtime2): runtime2 = 100.0\n",
    "    runtime_sim = 1.0 - abs(runtime1 - runtime2) / 200.0\n",
    "    runtime_sim = max(runtime_sim, 0.0)\n",
    "\n",
    "    context = np.array([genre_sim, year_diff, era_same, rating_diff, popularity_sim, runtime_sim])\n",
    "    return context\n",
    "\n",
    "def compute_feature_similarities(movie1_idx, movie2_idx, df):\n",
    "    m1 = df.iloc[movie1_idx]\n",
    "    m2 = df.iloc[movie2_idx]\n",
    "\n",
    "    overview_sim = cosine_similarity([m1['overview_vector']], [m2['overview_vector']])[0][0]\n",
    "    genre_sim = cosine_similarity([m1['genre_vector']], [m2['genre_vector']])[0][0]\n",
    "\n",
    "    actor_sim = cosine_similarity([m1['actor_vector']], [m2['actor_vector']])[0][0]\n",
    "    director_sim = cosine_similarity([m1['director_vector']], [m2['director_vector']])[0][0]\n",
    "\n",
    "    return np.array([overview_sim, genre_sim, actor_sim, director_sim])\n",
    "\n",
    "def compute_attention_similarity(movie1_idx, movie2_idx, df, attention_model):\n",
    "    context = compute_context_vector(movie1_idx, movie2_idx, df)\n",
    "    context_tensor = torch.FloatTensor(context).unsqueeze(0).to(device)\n",
    "\n",
    "    attention_model.eval()\n",
    "    with torch.no_grad():\n",
    "        attention_weights = attention_model(context_tensor).cpu().numpy()[0]\n",
    "\n",
    "    feature_sims = compute_feature_similarities(movie1_idx, movie2_idx, df)\n",
    "\n",
    "    final_similarity = np.dot(attention_weights, feature_sims)\n",
    "\n",
    "    return final_similarity, attention_weights\n",
    "\n",
    "print(\"Initializing attention model...\")\n",
    "attention_model = AttentionNetwork(context_dim=6, hidden_dims=[128, 64, 32], dropout=0.3)\n",
    "attention_model = attention_model.to(device)\n",
    "\n",
    "print(f\"Model architecture:\")\n",
    "print(attention_model)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in attention_model.parameters())}\")\n",
    "\n",
    "print(\"\\nTesting attention mechanism...\")\n",
    "test_sim, test_weights = compute_attention_similarity(0, 1, df, attention_model)\n",
    "print(f\"Test similarity: {test_sim:.4f}\")\n",
    "print(f\"Test attention weights: {test_weights}\")\n",
    "print(f\"Weight names: ['overview', 'genre', 'actor', 'director']\")\n",
    "\n",
    "print(\"\\nContext vector example:\")\n",
    "test_context = compute_context_vector(0, 1, df)\n",
    "print(f\"Context features: {test_context}\")\n",
    "print(f\"Context names: ['genre_sim', 'year_diff', 'era_same', 'rating_diff', 'popularity_sim', 'runtime_sim']\")"
   ],
   "id": "5f45adaf34cb1793",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing attention model...\n",
      "Model architecture:\n",
      "AttentionNetwork(\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Linear(in_features=32, out_features=4, bias=True)\n",
      "    (13): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "Model parameters: 11812\n",
      "\n",
      "Testing attention mechanism...\n",
      "Test similarity: 0.4620\n",
      "Test attention weights: [0.25838992 0.24908654 0.26302537 0.22949815]\n",
      "Weight names: ['overview', 'genre', 'actor', 'director']\n",
      "\n",
      "Context vector example:\n",
      "Context features: [0.8931759  0.         1.         0.08       0.77530338 0.885     ]\n",
      "Context names: ['genre_sim', 'year_diff', 'era_same', 'rating_diff', 'popularity_sim', 'runtime_sim']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:55:34.732588Z",
     "start_time": "2025-10-19T14:55:34.050588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VALIDATION_PAIRS = 1000\n",
    "\n",
    "print(\"Generating validation pairs...\")\n",
    "val_indices = val_df.index.tolist()\n",
    "np.random.shuffle(val_indices)\n",
    "\n",
    "validation_pairs = []\n",
    "ground_truth = []\n",
    "\n",
    "pairs_generated = 0\n",
    "attempts = 0\n",
    "max_attempts = VALIDATION_PAIRS * 10\n",
    "\n",
    "while pairs_generated < VALIDATION_PAIRS and attempts < max_attempts:\n",
    "    idx1 = np.random.choice(val_indices)\n",
    "    idx2 = np.random.choice(val_indices)\n",
    "\n",
    "    if idx1 != idx2:\n",
    "        movie1_idx = df.index.get_loc(idx1)\n",
    "        movie2_idx = df.index.get_loc(idx2)\n",
    "\n",
    "        m1 = df.loc[idx1]\n",
    "        m2 = df.loc[idx2]\n",
    "\n",
    "        if m1['is_high_rated'] and m2['is_high_rated']:\n",
    "            similarity_score = 1.0\n",
    "        elif not m1['is_high_rated'] and not m2['is_high_rated']:\n",
    "            genre_overlap = len(set(m1['genres_list']) & set(m2['genres_list'])) > 0\n",
    "            similarity_score = 0.5 if genre_overlap else 0.0\n",
    "        else:\n",
    "            similarity_score = 0.0\n",
    "\n",
    "        validation_pairs.append((movie1_idx, movie2_idx))\n",
    "        ground_truth.append(similarity_score)\n",
    "        pairs_generated += 1\n",
    "\n",
    "    attempts += 1\n",
    "\n",
    "print(f\"Generated {len(validation_pairs)} validation pairs\")\n",
    "print(f\"Ground truth distribution:\")\n",
    "print(f\"High similarity (1.0): {ground_truth.count(1.0)}\")\n",
    "print(f\"Medium similarity (0.5): {ground_truth.count(0.5)}\")\n",
    "print(f\"Low similarity (0.0): {ground_truth.count(0.0)}\")\n",
    "\n",
    "print(\"\\nSample pairs:\")\n",
    "for i in range(3):\n",
    "    m1_idx, m2_idx = validation_pairs[i]\n",
    "    m1_title = df.iloc[m1_idx]['title']\n",
    "    m2_title = df.iloc[m2_idx]['title']\n",
    "    gt = ground_truth[i]\n",
    "    print(f\"Pair {i+1}: '{m1_title}' vs '{m2_title}' - GT: {gt}\")"
   ],
   "id": "1a4ae7de2332a865",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation pairs...\n",
      "Generated 1000 validation pairs\n",
      "Ground truth distribution:\n",
      "High similarity (1.0): 107\n",
      "Medium similarity (0.5): 149\n",
      "Low similarity (0.0): 744\n",
      "\n",
      "Sample pairs:\n",
      "Pair 1: 'Last Hijack' vs 'Somewhere Between' - GT: 0.5\n",
      "Pair 2: 'Win/Win' vs 'Honeymoon' - GT: 0.5\n",
      "Pair 3: 'Eco-Pirate: The Story of Paul Watson' vs 'The Staircase II: The Last Chance' - GT: 0.5\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:55:36.569585Z",
     "start_time": "2025-10-19T14:55:34.742586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(predicted_similarities, ground_truth, k=5):\n",
    "    paired_data = list(zip(predicted_similarities, ground_truth))\n",
    "    paired_data.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    precision_at_k = sum(1 for i, (_, gt) in enumerate(paired_data[:k]) if gt >= 0.5) / k\n",
    "\n",
    "    ap_scores = []\n",
    "    for threshold in [0.5, 1.0]:\n",
    "        relevant_items = [i for i, gt in enumerate(ground_truth) if gt >= threshold]\n",
    "        if not relevant_items:\n",
    "            continue\n",
    "\n",
    "        precision_scores = []\n",
    "        for i, (_, gt) in enumerate(paired_data):\n",
    "            if gt >= threshold:\n",
    "                precision_at_i = sum(1 for j in range(i+1) if paired_data[j][1] >= threshold) / (i+1)\n",
    "                precision_scores.append(precision_at_i)\n",
    "\n",
    "        if precision_scores:\n",
    "            ap_scores.append(np.mean(precision_scores))\n",
    "\n",
    "    map_score = np.mean(ap_scores) if ap_scores else 0.0\n",
    "\n",
    "    diversity_score = np.std(predicted_similarities) if len(predicted_similarities) > 1 else 0.0\n",
    "\n",
    "    return precision_at_k, map_score, diversity_score\n",
    "\n",
    "def evaluate_attention_model(attention_model, validation_pairs, ground_truth):\n",
    "    attention_model.eval()\n",
    "    predicted_similarities = []\n",
    "\n",
    "    for movie1_idx, movie2_idx in validation_pairs:\n",
    "        try:\n",
    "            sim_score, _ = compute_attention_similarity(movie1_idx, movie2_idx, df, attention_model)\n",
    "            predicted_similarities.append(float(sim_score))\n",
    "        except:\n",
    "            predicted_similarities.append(0.0)\n",
    "\n",
    "    precision_k, map_score, diversity = compute_metrics(predicted_similarities, ground_truth)\n",
    "\n",
    "    combined_score = 0.6 * map_score + 0.3 * precision_k + 0.1 * diversity\n",
    "\n",
    "    return combined_score, precision_k, map_score, diversity\n",
    "\n",
    "print(\"Testing objective function with current model...\")\n",
    "current_score, prec, map_val, div = evaluate_attention_model(attention_model, validation_pairs, ground_truth)\n",
    "\n",
    "print(f\"Current model performance:\")\n",
    "print(f\"Combined Score: {current_score:.4f}\")\n",
    "print(f\"Precision@5: {prec:.4f}\")\n",
    "print(f\"MAP: {map_val:.4f}\")\n",
    "print(f\"Diversity: {div:.4f}\")\n",
    "\n",
    "print(f\"\\nObjective function weights: 0.6*MAP + 0.3*Precision@5 + 0.1*Diversity\")\n",
    "print(\"Ready for Bayesian Optimization...\")"
   ],
   "id": "3361048a96d3ddb9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing objective function with current model...\n",
      "Current model performance:\n",
      "Combined Score: 0.4378\n",
      "Precision@5: 0.8000\n",
      "MAP: 0.3177\n",
      "Diversity: 0.0716\n",
      "\n",
      "Objective function weights: 0.6*MAP + 0.3*Precision@5 + 0.1*Diversity\n",
      "Ready for Bayesian Optimization...\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:55:36.654585Z",
     "start_time": "2025-10-19T14:55:36.642585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skopt.space import Real, Integer\n",
    "\n",
    "parameter_space = [\n",
    "    Real(0.001, 0.1, name='learning_rate', prior='log-uniform'),\n",
    "    Real(0.1, 0.5, name='dropout_rate'),\n",
    "    Integer(32, 256, name='hidden_dim1'),\n",
    "    Integer(16, 128, name='hidden_dim2'),\n",
    "    Integer(8, 64, name='hidden_dim3'),\n",
    "    Real(0.4, 0.8, name='map_weight'),\n",
    "    Real(0.1, 0.4, name='precision_weight'),\n",
    "    Real(0.05, 0.2, name='diversity_weight'),\n",
    "    Integer(5, 50, name='training_epochs')\n",
    "]\n",
    "\n",
    "def create_optimized_model(params):\n",
    "    if isinstance(params[0], list):\n",
    "        params = [p[0] for p in params]\n",
    "\n",
    "    lr, dropout, h1, h2, h3, map_w, prec_w, div_w, epochs = params\n",
    "\n",
    "    model = AttentionNetwork(context_dim=6,\n",
    "                           hidden_dims=[int(h1), int(h2), int(h3)],\n",
    "                           dropout=float(dropout))\n",
    "    model = model.to(device)\n",
    "\n",
    "    config = {\n",
    "        'learning_rate': float(lr),\n",
    "        'map_weight': float(map_w),\n",
    "        'precision_weight': float(prec_w),\n",
    "        'diversity_weight': float(div_w),\n",
    "        'training_epochs': int(epochs)\n",
    "    }\n",
    "\n",
    "    return model, config\n",
    "\n",
    "test_model, test_config = create_optimized_model([param.rvs() for param in parameter_space])\n",
    "print(f\"Parameter space ready. Test model: {sum(p.numel() for p in test_model.parameters())} params\")"
   ],
   "id": "28fb0b44a85e765a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter space ready. Test model: 9337 params\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T14:56:23.531137Z",
     "start_time": "2025-10-19T14:55:36.686587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_attention_model(model, config):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    for epoch in range(config['training_epochs']):\n",
    "        total_loss = 0\n",
    "        batch_pairs = np.random.choice(len(validation_pairs), size=min(50, len(validation_pairs)), replace=False)\n",
    "\n",
    "        for idx in batch_pairs:\n",
    "            movie1_idx, movie2_idx = validation_pairs[idx]\n",
    "            target_sim = torch.FloatTensor([ground_truth[idx]]).to(device)\n",
    "\n",
    "            try:\n",
    "                context = compute_context_vector(movie1_idx, movie2_idx, df)\n",
    "                context_tensor = torch.FloatTensor(context).unsqueeze(0).to(device)\n",
    "\n",
    "                attention_weights = model(context_tensor)\n",
    "                feature_sims = compute_feature_similarities(movie1_idx, movie2_idx, df)\n",
    "                feature_sims_tensor = torch.FloatTensor(feature_sims).unsqueeze(0).to(device)\n",
    "\n",
    "                predicted_sim = torch.sum(attention_weights * feature_sims_tensor, dim=1)\n",
    "                loss = nn.MSELoss()(predicted_sim, target_sim)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "@use_named_args(parameter_space)\n",
    "def objective(**params):\n",
    "    try:\n",
    "        param_values = [params[param.name] for param in parameter_space]\n",
    "        model, config = create_optimized_model(param_values)\n",
    "\n",
    "        train_attention_model(model, config)\n",
    "\n",
    "        predicted_similarities = []\n",
    "        for movie1_idx, movie2_idx in validation_pairs:\n",
    "            try:\n",
    "                sim_score, _ = compute_attention_similarity(movie1_idx, movie2_idx, df, model)\n",
    "                predicted_similarities.append(float(sim_score))\n",
    "            except:\n",
    "                predicted_similarities.append(0.0)\n",
    "\n",
    "        paired_data = list(zip(predicted_similarities, ground_truth))\n",
    "        paired_data.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        precision_at_5 = sum(1 for i, (_, gt) in enumerate(paired_data[:5]) if gt >= 0.5) / 5\n",
    "\n",
    "        relevant_indices = [i for i, gt in enumerate(ground_truth) if gt >= 0.5]\n",
    "        if relevant_indices:\n",
    "            ap_scores = []\n",
    "            for i, (_, gt) in enumerate(paired_data):\n",
    "                if gt >= 0.5:\n",
    "                    precision_at_i = sum(1 for j in range(i+1) if paired_data[j][1] >= 0.5) / (i+1)\n",
    "                    ap_scores.append(precision_at_i)\n",
    "            map_score = np.mean(ap_scores) if ap_scores else 0.0\n",
    "        else:\n",
    "            map_score = 0.0\n",
    "\n",
    "        diversity = np.std(predicted_similarities) if len(predicted_similarities) > 1 else 0.0\n",
    "\n",
    "        combined_score = (config['map_weight'] * map_score +\n",
    "                         config['precision_weight'] * precision_at_5 +\n",
    "                         config['diversity_weight'] * diversity)\n",
    "\n",
    "        return -combined_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in objective: {e}\")\n",
    "        return -0.1\n",
    "\n",
    "print(\"Starting Bayesian Optimization with full training...\")\n",
    "print(f\"Baseline score: {current_score:.4f}\")\n",
    "\n",
    "result = gp_minimize(objective, parameter_space, n_calls=15,\n",
    "                    random_state=42, acq_func='EI', verbose=True)\n",
    "\n",
    "print(f\"\\nOptimization completed!\")\n",
    "print(f\"Best score: {-result.fun:.4f}\")\n",
    "print(f\"Improvement: {-result.fun - current_score:.4f}\")\n",
    "\n",
    "best_params = result.x\n",
    "best_model, best_config = create_optimized_model(best_params)\n",
    "train_attention_model(best_model, best_config)\n",
    "\n",
    "print(f\"\\nBest parameters:\")\n",
    "for i, param in enumerate(parameter_space):\n",
    "    value = best_params[i]\n",
    "    if isinstance(value, list):\n",
    "        value = value[0]\n",
    "    print(f\"{param.name}: {value}\")\n",
    "\n",
    "final_score, final_prec, final_map, final_div = evaluate_attention_model(best_model, validation_pairs, ground_truth)\n",
    "print(f\"\\nFinal performance:\")\n",
    "print(f\"Combined Score: {final_score:.4f}\")\n",
    "print(f\"Precision@5: {final_prec:.4f}\")\n",
    "print(f\"MAP: {final_map:.4f}\")\n",
    "print(f\"Diversity: {final_div:.4f}\")\n",
    "\n",
    "optimized_attention_model = best_model"
   ],
   "id": "9dbf96b278290419",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian Optimization with full training...\n",
      "Baseline score: 0.4378\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 3.6156\n",
      "Function value obtained: -0.4252\n",
      "Current minimum: -0.4252\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 2.2350\n",
      "Function value obtained: -0.6534\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 2.8700\n",
      "Function value obtained: -0.3423\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 2.9760\n",
      "Function value obtained: -0.5249\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 2.6510\n",
      "Function value obtained: -0.5095\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 3.8780\n",
      "Function value obtained: -0.5760\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 3.2940\n",
      "Function value obtained: -0.6499\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 2.8170\n",
      "Function value obtained: -0.3556\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 3.8150\n",
      "Function value obtained: -0.5863\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 3.0110\n",
      "Function value obtained: -0.4844\n",
      "Current minimum: -0.6534\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.4180\n",
      "Function value obtained: -0.7399\n",
      "Current minimum: -0.7399\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3880\n",
      "Function value obtained: -0.7434\n",
      "Current minimum: -0.7434\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3930\n",
      "Function value obtained: -0.7382\n",
      "Current minimum: -0.7434\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4140\n",
      "Function value obtained: -0.7385\n",
      "Current minimum: -0.7434\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4180\n",
      "Function value obtained: -0.7436\n",
      "Current minimum: -0.7436\n",
      "\n",
      "Optimization completed!\n",
      "Best score: 0.7436\n",
      "Improvement: 0.3058\n",
      "\n",
      "Best parameters:\n",
      "learning_rate: 0.001\n",
      "dropout_rate: 0.1\n",
      "hidden_dim1: 32\n",
      "hidden_dim2: 16\n",
      "hidden_dim3: 8\n",
      "map_weight: 0.8\n",
      "precision_weight: 0.4\n",
      "diversity_weight: 0.11492081020470123\n",
      "training_epochs: 5\n",
      "\n",
      "Final performance:\n",
      "Combined Score: 0.4346\n",
      "Precision@5: 0.8000\n",
      "MAP: 0.3142\n",
      "Diversity: 0.0604\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T15:00:07.906922Z",
     "start_time": "2025-10-19T14:56:23.608138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_movie_recommendations(movie_title, model, top_k=10):\n",
    "    try:\n",
    "        movie_row = df[df['title'].str.contains(movie_title, case=False, na=False)].iloc[0]\n",
    "        target_idx = df.index.get_loc(movie_row.name)\n",
    "\n",
    "        similarities = []\n",
    "        for idx in df.index:\n",
    "            if idx != movie_row.name:\n",
    "                candidate_idx = df.index.get_loc(idx)\n",
    "                try:\n",
    "                    sim_score, attention_weights = compute_attention_similarity(target_idx, candidate_idx, df, model)\n",
    "                    similarities.append((idx, sim_score, attention_weights))\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        recommendations = []\n",
    "        for idx, sim_score, att_weights in similarities[:top_k]:\n",
    "            movie_info = df.loc[idx]\n",
    "            recommendations.append({\n",
    "                'title': movie_info['title'],\n",
    "                'year': movie_info['year'],\n",
    "                'genres': movie_info['genres_str'],\n",
    "                'similarity': sim_score,\n",
    "                'attention_weights': att_weights,\n",
    "                'rating': movie_info['vote_average']\n",
    "            })\n",
    "\n",
    "        return movie_row, recommendations\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting recommendations: {e}\")\n",
    "        return None, []\n",
    "\n",
    "def analyze_attention_patterns(model, sample_pairs=50):\n",
    "    attention_analysis = {\n",
    "        'high_similarity': [],\n",
    "        'medium_similarity': [],\n",
    "        'low_similarity': []\n",
    "    }\n",
    "\n",
    "    for i in range(min(sample_pairs, len(validation_pairs))):\n",
    "        movie1_idx, movie2_idx = validation_pairs[i]\n",
    "        gt = ground_truth[i]\n",
    "\n",
    "        try:\n",
    "            _, attention_weights = compute_attention_similarity(movie1_idx, movie2_idx, df, model)\n",
    "\n",
    "            if gt >= 0.8:\n",
    "                attention_analysis['high_similarity'].append(attention_weights)\n",
    "            elif gt >= 0.3:\n",
    "                attention_analysis['medium_similarity'].append(attention_weights)\n",
    "            else:\n",
    "                attention_analysis['low_similarity'].append(attention_weights)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    avg_attention = {}\n",
    "    for category, weights_list in attention_analysis.items():\n",
    "        if weights_list:\n",
    "            avg_attention[category] = np.mean(weights_list, axis=0)\n",
    "\n",
    "    return avg_attention\n",
    "\n",
    "print(\"=== FINAL EVALUATION ON TEST SET ===\")\n",
    "if len(test_df) > 10:\n",
    "    test_indices = test_df.index.tolist()[:50]  # Sample from test set\n",
    "    test_pairs = []\n",
    "    test_ground_truth = []\n",
    "\n",
    "    for i in range(min(100, len(test_indices))):\n",
    "        idx1 = np.random.choice(test_indices)\n",
    "        idx2 = np.random.choice(test_indices)\n",
    "        if idx1 != idx2:\n",
    "            movie1_idx = df.index.get_loc(idx1)\n",
    "            movie2_idx = df.index.get_loc(idx2)\n",
    "            m1, m2 = df.loc[idx1], df.loc[idx2]\n",
    "\n",
    "            if m1['is_high_rated'] and m2['is_high_rated']:\n",
    "                gt = 1.0\n",
    "            elif len(set(m1['genres_list']) & set(m2['genres_list'])) > 0:\n",
    "                gt = 0.5\n",
    "            else:\n",
    "                gt = 0.0\n",
    "\n",
    "            test_pairs.append((movie1_idx, movie2_idx))\n",
    "            test_ground_truth.append(gt)\n",
    "\n",
    "    test_score, test_prec, test_map, test_div = evaluate_attention_model(optimized_attention_model, test_pairs, test_ground_truth)\n",
    "    print(f\"Test Set Performance:\")\n",
    "    print(f\"Combined Score: {test_score:.4f}\")\n",
    "    print(f\"Precision@5: {test_prec:.4f}\")\n",
    "    print(f\"MAP: {test_map:.4f}\")\n",
    "    print(f\"Diversity: {test_div:.4f}\")\n",
    "else:\n",
    "    print(\"Test set too small for comprehensive evaluation\")\n",
    "\n",
    "print(\"\\n=== MOVIE RECOMMENDATIONS ===\")\n",
    "sample_movies = ['Toy Story', 'The Matrix', 'Titanic', 'Avatar']\n",
    "\n",
    "for movie_title in sample_movies:\n",
    "    print(f\"\\n--- Recommendations for '{movie_title}' ---\")\n",
    "    target_movie, recs = get_movie_recommendations(movie_title, optimized_attention_model, top_k=5)\n",
    "\n",
    "    if target_movie is not None:\n",
    "        print(f\"Target: {target_movie['title']} ({target_movie['year']}) - {target_movie['genres_str']}\")\n",
    "\n",
    "        for i, rec in enumerate(recs, 1):\n",
    "            att_str = f\"[{rec['attention_weights'][0]:.2f}, {rec['attention_weights'][1]:.2f}, {rec['attention_weights'][2]:.2f}, {rec['attention_weights'][3]:.2f}]\"\n",
    "            print(f\"{i}. {rec['title']} ({rec['year']}) - Sim: {rec['similarity']:.3f} - Att: {att_str}\")\n",
    "            print(f\"   Genres: {rec['genres']}\")\n",
    "\n",
    "print(\"\\n=== ATTENTION PATTERN ANALYSIS ===\")\n",
    "attention_patterns = analyze_attention_patterns(optimized_attention_model)\n",
    "\n",
    "feature_names = ['Overview', 'Genre', 'Actor', 'Director']\n",
    "for category, avg_weights in attention_patterns.items():\n",
    "    print(f\"\\n{category.replace('_', ' ').title()} pairs:\")\n",
    "    for i, weight in enumerate(avg_weights):\n",
    "        print(f\"  {feature_names[i]}: {weight:.3f}\")\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Baseline model: {current_score:.4f}\")\n",
    "print(f\"Optimized model: {final_score:.4f}\")\n",
    "print(f\"Improvement: {final_score - current_score:.4f} ({((final_score - current_score) / current_score * 100):+.1f}%)\")"
   ],
   "id": "d448f6b1186ccaca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL EVALUATION ON TEST SET ===\n",
      "Test Set Performance:\n",
      "Combined Score: 0.6940\n",
      "Precision@5: 1.0000\n",
      "MAP: 0.6484\n",
      "Diversity: 0.0490\n",
      "\n",
      "=== MOVIE RECOMMENDATIONS ===\n",
      "\n",
      "--- Recommendations for 'Toy Story' ---\n",
      "Target: Toy Story (1995) - Animation Comedy Family\n",
      "1. Partysaurus Rex (2012) - Sim: 0.677 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Animation Comedy Family Fantasy\n",
      "2. Toy Story of Terror! (2013) - Sim: 0.677 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Animation Comedy Family\n",
      "3. Toy Story 2 (1999) - Sim: 0.638 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Animation Comedy Family\n",
      "4. Toy Story That Time Forgot (2014) - Sim: 0.617 - Att: [0.28, 0.20, 0.22, 0.30]\n",
      "   Genres: Animation Family\n",
      "5. Hawaiian Vacation (2011) - Sim: 0.607 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Animation Family\n",
      "\n",
      "--- Recommendations for 'The Matrix' ---\n",
      "Target: The Matrix (1999) - Action Science Fiction\n",
      "1. The Matrix Revolutions (2003) - Sim: 0.668 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Adventure Action Thriller Science Fiction\n",
      "2. The Matrix Reloaded (2003) - Sim: 0.652 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Adventure Action Thriller Science Fiction\n",
      "3. The Animatrix (2003) - Sim: 0.622 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Animation Science Fiction\n",
      "4. Kid's Story (2003) - Sim: 0.620 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Science Fiction Animation\n",
      "5. A Detective Story (2003) - Sim: 0.569 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Science Fiction Animation\n",
      "\n",
      "--- Recommendations for 'Titanic' ---\n",
      "Target: Titanic (1997) - Drama Romance Thriller\n",
      "1. Revolutionary Road (2008) - Sim: 0.590 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Drama Romance\n",
      "2. Lake Consequence (1993) - Sim: 0.553 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Drama Romance\n",
      "3. Blue Seduction (2009) - Sim: 0.550 - Att: [0.28, 0.20, 0.22, 0.30]\n",
      "   Genres: Thriller Romance\n",
      "4. Hideous Kinky (1998) - Sim: 0.544 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Romance Drama\n",
      "5. Jude (1996) - Sim: 0.543 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Drama Romance\n",
      "\n",
      "--- Recommendations for 'Avatar' ---\n",
      "Target: Avatar (2009) - Action Adventure Fantasy Science Fiction\n",
      "1. Rakka (2017) - Sim: 0.669 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Action Science Fiction\n",
      "2. Vamps (2012) - Sim: 0.597 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Comedy Romance Horror\n",
      "3. Snow White: A Tale of Terror (1997) - Sim: 0.592 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Fantasy Horror\n",
      "4. Avatar 2 (2020) - Sim: 0.584 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Action Adventure Fantasy Science Fiction\n",
      "5. Alien (1992) - Sim: 0.564 - Att: [0.27, 0.20, 0.22, 0.30]\n",
      "   Genres: Science Fiction Action Horror\n",
      "\n",
      "=== ATTENTION PATTERN ANALYSIS ===\n",
      "\n",
      "High Similarity pairs:\n",
      "  Overview: 0.273\n",
      "  Genre: 0.202\n",
      "  Actor: 0.222\n",
      "  Director: 0.302\n",
      "\n",
      "Medium Similarity pairs:\n",
      "  Overview: 0.274\n",
      "  Genre: 0.202\n",
      "  Actor: 0.222\n",
      "  Director: 0.302\n",
      "\n",
      "Low Similarity pairs:\n",
      "  Overview: 0.274\n",
      "  Genre: 0.202\n",
      "  Actor: 0.223\n",
      "  Director: 0.301\n",
      "\n",
      "=== SUMMARY ===\n",
      "Baseline model: 0.4378\n",
      "Optimized model: 0.4346\n",
      "Improvement: -0.0032 (-0.7%)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T15:00:08.060923Z",
     "start_time": "2025-10-19T15:00:08.057922Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "20832388e0b132b5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
